{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 | Data processing & missing value imputations\n",
    "\n",
    "Session recording:  https://youtu.be/-IcXBQi6SbA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration is always the first step of model building. \n",
    "\n",
    "You cannot assume the data you were provided to be flawless. \n",
    "\n",
    "Data collection, pre-processing and cleaning is majority of work we do on DS projects. \n",
    "\n",
    "Data originates from multiple sources.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**\n",
    "\n",
    "*Possible data sources: excel, csv, json, yaml, database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_in_cm</th>\n",
       "      <th>sepal_width_in_cm</th>\n",
       "      <th>petal_length_in_cm</th>\n",
       "      <th>petal_width_in_cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length_in_cm  sepal_width_in_cm  petal_length_in_cm  \\\n",
       "0                 5.1                3.5                 1.4   \n",
       "1                 4.9                3.0                 1.4   \n",
       "2                 4.7                3.2                 1.3   \n",
       "3                 4.6                3.1                 1.5   \n",
       "4                 5.0                3.6                 1.4   \n",
       "\n",
       "   petal_width_in_cm        class  \n",
       "0                0.2  Iris-setosa  \n",
       "1                0.2  Iris-setosa  \n",
       "2                0.2  Iris-setosa  \n",
       "3                0.2  Iris-setosa  \n",
       "4                0.2  Iris-setosa  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "# Define the column names\n",
    "col_names = [\"sepal_length_in_cm\" , \n",
    "            \"sepal_width_in_cm\" ,\n",
    "            \"petal_length_in_cm\" ,\n",
    "            \"petal_width_in_cm\" ,\n",
    "            \"class\"]\n",
    "\n",
    "# Read data from URL\n",
    "iris_data = pd.read_csv(url, names=col_names)\n",
    "iris_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore data**\n",
    "\n",
    "```\n",
    "df.head()\n",
    "df.tail()\n",
    "df.columns\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe() \n",
    "df.describe(include=[\"object\", \"bool\"])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column types**\n",
    "\n",
    "- numerical (income, age)\n",
    "- string, factor (F/M, CZ, SK...)\n",
    "- bool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df[\"active_status\"].value_counts()\n",
    "pd.crosstab(df[\"country\"], df[\"ethnicity\"]\n",
    "pd.crosstab(df[\"country\"], df[\"ethnicity\"], normalize=True)\n",
    "df.pivot_table([\"length_of_service\" , \n",
    "                \"total_compensation\" ], \n",
    "                [\"generation\"], \n",
    "                aggfunc=\"mean\",)\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify feature type**\n",
    "\n",
    "`df['date_of_birth'] = pd.to_datetime(df[ 'date_of_birth’]`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select useful columns**\n",
    "\n",
    "```\n",
    "columns_to_drop = [ \"active_status\", \n",
    "                    \"company\", \n",
    "                    \"hire_date\", \n",
    "                    \"organization_level\" , \n",
    "                    \"termination_category\", \n",
    "                    \"termination_date\", \n",
    "                    \"termination_reason\" ,\n",
    "                     \"worker_type\"]\n",
    "df.drop(columns=columns_to_drop, inplace= True)\n",
    "```\n",
    "\n",
    "```\n",
    "columns_to_select = [ \"employee_id\", \n",
    "                    \"gender\", \n",
    "                    \"ethnicity\", \n",
    "                    \"is_manager\", \n",
    "                    \"job_level\"]\n",
    "df[columns_to_select]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering observation**\n",
    "\n",
    "`df.sort_values(by=[ \"location\", \"length_of_service\" ], ascending=[True, False]).head()`\n",
    "\n",
    "`df[df['gender'] == 'Female'].head()`\n",
    "\n",
    "- AND `&`, OR `|`, NOT `~`\n",
    "- `==`, `!=`, `>`, `<`, `>=`, `<=`\n",
    "- .isin()\n",
    "- .between()\n",
    "- .str.contains('M’)\n",
    "- .str.startswith('A’)\n",
    "- .str.endswith('ez')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data format**\n",
    "\n",
    "- wide (1 OBS = All Employee Information)\n",
    "- long (1 OBS = PersonID + Variable)\n",
    "    - data processing in bulk (e.g., conversion to numeric), \n",
    "    - visualizations of multiple variables in one plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding of non-numeric data**\n",
    "\n",
    "- Categorical variables need to be transformed into numeric ones.\n",
    "- Usually, one category is dropped (use only male gender here) to avoid multicollinearity.\n",
    "\n",
    "`pd.get_dummies`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating new column based on other columns**\n",
    "\n",
    "- arithmetic operations: addition, subtraction, multiplication, division (+,-,/,*)\n",
    "- conditional statements: IF, ELSE, ELSEIF\n",
    "- text transformation `.str`, `.split()`, `.replace()`,\n",
    "- regex operations `.findall()`, `.extract()`\n",
    "- method `.apply()`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaing\n",
    "\n",
    "Check variables distributions, outliers, remove such observations or treat them like missing values, visualisation and exploration.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Outliers\n",
    "- Z-scores \n",
    "    - position of a particular data point relative to the mean of a data set\n",
    "    - `z = (x - μ) / σ`\n",
    "    - `z = (data point - mean) / standard devation`\n",
    "- IQR method\n",
    "    - IQR = Q3 - Q1\n",
    "- Box plots\n",
    "\n",
    "\n",
    "### Handling Outliers\n",
    "- Remove observations\n",
    "- Treat as missing values\n",
    "- Replace with less extreme\n",
    "- Data transformation (scaling)\n",
    "\n",
    "### Missing Values\n",
    "- Listwise deletion\n",
    "- Imputation (mean, median, mode)\n",
    "- Interpolation\n",
    "- Predictive models\n",
    "\n",
    "\n",
    "### Univariate Visualization\n",
    "- Histograms, density plots\n",
    "- Box plots, violin plots\n",
    "- Bar charts, pie charts\n",
    "\n",
    "### Bivariate visualizations\n",
    "- Scatter plots\n",
    "- Line charts, area charts\n",
    "-  Heatmaps, bubble charts\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation\n",
    "\n",
    "**Types of Data Aggregations**\n",
    "- Sum, average, count\n",
    "- Min, max, median\n",
    "- Standard deviation, variance\n",
    "\n",
    "**Grouping Data**\n",
    "- Categorical variables\n",
    "- Binning continuous variables\n",
    "- Time-based variables\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling & normalization\n",
    "\n",
    "Turn columns to the same scales\n",
    "\n",
    "Normalising\n",
    "- Spreading cols in [0,1]\n",
    "- `y = (x – col_min) / (col_max – col_min)`\n",
    "\n",
    "Scaling\n",
    "- Transform cols to get mean = 0, std = 1\n",
    "- `y = (x – col_mean) / col_std`\n",
    "\n",
    "\n",
    "**Why Scaling/Normalising before Algo?**\n",
    "- Visualise\n",
    "- Some algos get biased when not scaled/norm...\n",
    "- Some algos require it\n",
    "- Sometimes numerical requirements to run\n",
    "\n",
    "\n",
    "**Scaling/Normalising comparison**\n",
    "- Some algos do not need either (Random forests...)\n",
    "- Never harms to scale/normalise\n",
    "- No clear guideline to choose scale/normalise\n",
    "- Can run both, run models and compare performance...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values\n",
    "\n",
    "Some algorithms will not work if you pass data with missing observations to them.\n",
    "\n",
    "Some algorithms will work if you pass missing observations but will have default behavior which might not necessary the right one for your case.\n",
    "\n",
    "Having missing data will impact results of your analysis.\n",
    "\n",
    "### Types of missing values\n",
    "- MCAR missing completely at random - Error entering observation to the system\n",
    "- MAR missing at random - Stereotype – women are more likely to not report \n",
    "their weigh\n",
    "- MNAR missing not at random - Society stigma – people with big weight would \n",
    "not report their weight\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Handling Missing Values\n",
    "\n",
    "\n",
    "**Deduce missting values**\n",
    "- Some missing values can be deduced\n",
    "\n",
    "**Remove observations/variables**\n",
    "```\n",
    "# Track obs w/ too many NAs\n",
    "threshold = 0.5\n",
    "nbr_cols = len(df.columns)\n",
    "obs_to_keep = df.isnull().sum(axis=0) / nbr_cols   <  threshold\n",
    "df = df[obs_to_keep]\n",
    "\n",
    "col_to_drop = df.columns[df.isnull().sum(axis=1) / nbr_obs   >  threshold]\n",
    "df = df.drop(col_to_drop, axis=1)\n",
    "```\n",
    "\n",
    "When variable deletion is unavoidable\n",
    "- Variable has way too many values missing and variable does not correlate strongly with anything else\n",
    "    - losing too many observations when building a model \n",
    "    - imputation is too imprecise\n",
    "- Variable has too many categories and many values missing\n",
    "    - Not much additional value for a model and we still lose observations\n",
    "- Impact: no conclusions about that variable, possible bias to the model\n",
    "\n",
    "\n",
    "**Simple imputation methods**\n",
    "\n",
    "Advantages: fast computation, easy to understand, can have very good performance\n",
    "\n",
    "Disadvantages: can be imprecise, can lowewr variance of data, for time series you need to know at least one data point\n",
    "\n",
    "Methods:\n",
    "- mean or median\n",
    "    - suitable when there is no trend and no seasonality\n",
    "    - DRAWBACK:\n",
    "        - Spike at mean value & low variance\n",
    "        - Assumption of no trend may not hold\n",
    "- linear interpolation\n",
    "    - suitable when there is some trend and no seasonality\n",
    "    - DRAWBACK:\n",
    "        - Assumes the trend is linear\n",
    "        - At least two values are needed per individual\n",
    "\n",
    "- observation carry-over\n",
    "    - Last Observation Carried Forward, Next Observation Carried Backward\n",
    "        - DRAWBACK:\n",
    "            - Overestimation/Underestimation of variable value \n",
    "            - At least one value per individual needed to get some imputed values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Advanced imputation methods**\n",
    "- Use algorithm to estimate relationship between selected variable and all other variables.\n",
    "- Predict missing values of selected variable based on the estimated relationship with all other variables.\n",
    "- Most methods work well if data is missing completely at random\n",
    "- Not all methods can accommodate missingness not at random\n",
    "- Examples: *linear regression, desision trees, random forest, KNN*\n",
    "\n",
    "Disadvantages: \n",
    "- Computation can take really long time sometimes\n",
    "- Hard to track down how exactly the given value was calculated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Selection of the best method**\n",
    "1. Find set of data without missing values within your dataset \n",
    "2. Artificially create missing values within your dataset\n",
    "3. Use any method you want to impute those missing values\n",
    "4. Compare real vs imputed values MAPE (mean absolute percentage error), preserved \n",
    "correlation\n",
    "5. Choose the best performing method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
